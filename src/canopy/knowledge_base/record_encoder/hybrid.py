import logging
from functools import cached_property
from typing import List, Optional

from pinecone_text.dense import OpenAIEncoder
from pinecone_text.dense.base_dense_ecoder import BaseDenseEncoder
from pinecone_text.hybrid import hybrid_convex_scale
from pinecone_text.sparse import BM25Encoder

from .base import RecordEncoder
from canopy.knowledge_base.models import KBQuery, KBEncodedDocChunk, KBDocChunk
from canopy.models.data_models import Query

logger = logging.getLogger(__name__)


class HybridRecordEncoder(RecordEncoder):
    """
    HybridRecordEncoder is a subclass of RecordEncoder that generates sparse and dense vector representation of
    documents` chunks and textual queries.

    The dense representation generated by the `HybridRecordEncoder` is a list of floats in a given dimension.
    The sparse representation generated by the `HybridRecordEncoder` is a `SparseVector`.

    HybridRecordEncoder uses BaseDenseEncoder for dense encoding and BM25Encoder for sparse encoding.

    Alpha is a parameter that controls the weight of the dense vector in the hybrid representation.
    If alpha is 1, the query vector will be the dense vector. The default value of alpha is 0.5.

    For more information about the encoders see: https://github.com/pinecone-io/pinecone-text

    """  # noqa: E501

    def __init__(self,
                 dense_encoder: BaseDenseEncoder = None,
                 alpha: float = 0.5,
                 bm_25_encoder_df_path: Optional[str] = None,
                 **kwargs):
        """
        Initialize the encoder.

        Args:
            dense_encoder: A BaseDenseEncoder to encode the text.
            alpha: The weight of the dense vector in the hybrid representation (between 0 and 1).
            bm_25_encoder_df_path: The path to the file that contains the document frequencies of the BM25Encoder.\
            You can create this file by fitting the BM25Encoder on a corpus of documents and calling `dump`\
            on the encoder.
            **kwargs: Additional arguments to pass to the RecordEncoder.
        """  # noqa: E501

        if not 0 < alpha <= 1:
            raise ValueError("Alpha must be between 0 (excluded) and 1 (included)")

        super().__init__(**kwargs)
        if dense_encoder:
            if not isinstance(dense_encoder, BaseDenseEncoder):
                raise TypeError(
                    f"dense_encoder must be an instance of BaseDenseEncoder, "
                    f"not {type(dense_encoder)}"
                )
            self._dense_encoder = dense_encoder
        else:
            self._dense_encoder = OpenAIEncoder()
        self._bm_25_encoder_df_path = bm_25_encoder_df_path
        self._alpha = alpha

    @cached_property
    def _sparse_encoder(self) -> BM25Encoder:
        logger.info("Loading the document frequencies for the BM25Encoder...")
        if self._bm_25_encoder_df_path is None:
            encoder = BM25Encoder.default()
        else:
            encoder = BM25Encoder().load(self._bm_25_encoder_df_path)
        logger.info("Finished loading the document frequencies for the BM25Encoder.")
        return encoder

    def _encode_documents_batch(self,
                                documents: List[KBDocChunk]
                                ) -> List[KBEncodedDocChunk]:
        """
        Encode a batch of documents, takes a list of KBDocChunk and returns a list of KBEncodedDocChunk.

        Args:
            documents: A list of KBDocChunk to encode.
        Returns:
            encoded chunks: A list of KBEncodedDocChunk,
            with the `values` containing the generated dense vector and
            `sparse_values` containing the generated sparse vector.
        """  # noqa: E501
        texts = [d.text for d in documents]
        dense_values = self._dense_encoder.encode_documents(texts)
        sparse_values = self._sparse_encoder.encode_documents(texts)
        return [
            KBEncodedDocChunk(**d.dict(), values=v, sparse_values=sv) for d, v, sv in
            zip(documents, dense_values, sparse_values)
        ]

    def _encode_queries_batch(self, queries: List[Query]) -> List[KBQuery]:
        """
        Encode a batch of queries, takes a list of Query and returns a list of KBQuery.
        Args:
            queries: A list of Query to encode.
        Returns:
            encoded queries: A list of KBQuery, with the `values` containing the generated dense vector with the weight
            alpha and `sparse_values` containing the generated sparse vector with the weight (1 - alpha).
        """  # noqa: E501

        texts = [q.text for q in queries]
        dense_values = self._dense_encoder.encode_queries(texts)
        sparse_values = self._sparse_encoder.encode_queries(texts)
        scaled_values = [
            hybrid_convex_scale(v, sv, self._alpha) for v, sv in
            zip(dense_values, sparse_values)
        ]

        return [KBQuery(**q.dict(), values=v, sparse_values=sv) for q, (v, sv) in
                zip(queries, scaled_values)]

    async def _aencode_documents_batch(self,
                                       documents: List[KBDocChunk]
                                       ) -> List[KBEncodedDocChunk]:
        raise NotImplementedError

    async def _aencode_queries_batch(self, queries: List[Query]) -> List[KBQuery]:
        raise NotImplementedError
