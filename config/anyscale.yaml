# ===========================================================
#            Configuration file for Canopy Server
# ===========================================================
query_builder_prompt: &query_builder_prompt |
  Your task is to formulate search queries for a search engine, to assist in responding to the user's question.
  You should break down complex questions into sub-queries if needed.
# -------------------------------------------------------------------------------------------
# Tokenizer configuration
# A Tokenizer singleton instance must be initialized before initializing any other components
# -------------------------------------------------------------------------------------------
tokenizer:
  type: LlamaTokenizer                 # Options: [OpenAITokenizer, LlamaTokenizer]
  params:
    model_name: openlm-research/open_llama_7b_v2

chat_engine:
  llm: &llm
    type: AnyscaleLLM                     # Options: [OpenAILLM, AnyscaleLLM]
    params:
      model_name: meta-llama/Llama-2-7b-chat-hf         # The name of the model to use.
      
  # --------------------------------------------------------------------
  # Configuration for the QueryBuilder subcomponent of the chat engine.
  # The query builder is responsible for generating textual queries given user message history.
  # --------------------------------------------------------------------
  query_builder:
    type: CondensedQueryGenerator     # Options: [FunctionCallingQueryGenerator, LastMessageQueryGenerator, CondensedQueryGenerator]