tokenizer:
  type: OpenAITokenizer
  params:
    model_name: gpt-3.5-turbo

knowledge_base:
  params:
    default_top_k: 5

  record_encoder:
    type: OpenAIEncoder
    params:
      model_name: "text-embedding-ada-002"
      batch_size: 100

  chunker:
    type: MarkdownChunker
    params:
      chunk_size: 256
      chunk_overlap: 0
      keep_separator: true

context_engine:
  context_builder:
    type: StuffingContextBuilder

  params:
    global_metadata_filter: null # An optional metadata filter to apply to all queries

llm:
  type: OpenAILLM
  params:
    model_name: gpt-3.5-turbo
    model_params: null # Model-specific parameters. May change depending on the model.

chat_engine:
  params:
    max_prompt_tokens: 3000
    max_generated_tokens: null # Will use the LLM's default max generated tokens
    max_context_tokens: 2500
    system_prompt: null  # Will use the default system prompt
    history_pruning: recent  # Options: [raise, recent]
    min_history_messages: 1

  query_builder:
    type: FunctionCallingQueryGenerator
    params:
      top_k: 5
      prompt: null  # Will use the default prompt
      function_description: null  # Will use the default function description